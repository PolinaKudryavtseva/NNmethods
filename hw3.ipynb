{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eda05b73dbdb493c80caf702a69910a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_25b25743916d4577aeb80fd019b87565",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5cb300d3565045e8acf04defc9c6538b",
              "IPY_MODEL_3c610d758f32485c9369d1b2feba51ff",
              "IPY_MODEL_b701d8da808a4472bf98b621707454c4"
            ]
          }
        },
        "25b25743916d4577aeb80fd019b87565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5cb300d3565045e8acf04defc9c6538b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_01f133cb0b3c44c89f9494c324a84bab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Epoch 1:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_087c1c5ce3554448931d85f77fb816ae"
          }
        },
        "3c610d758f32485c9369d1b2feba51ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9592175843e7493cb966c56440c70a26",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 18782,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d4b6751654304ed2a11384e95a3880d4"
          }
        },
        "b701d8da808a4472bf98b621707454c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_65c382420f22402fa2bfd0bc39d33bd3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/18782 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b95aa615b5054fca948342d40695ca2c"
          }
        },
        "01f133cb0b3c44c89f9494c324a84bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "087c1c5ce3554448931d85f77fb816ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9592175843e7493cb966c56440c70a26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d4b6751654304ed2a11384e95a3880d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65c382420f22402fa2bfd0bc39d33bd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b95aa615b5054fca948342d40695ca2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLLRxBoXUrKy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import torch\n",
        "import numpy as np\n",
        "import gensim\n",
        "import torch.nn.functional as F\n",
        "from nltk import word_tokenize\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn\n",
        "from tqdm.auto import tqdm\n",
        "from torchmetrics.functional import f1, recall, accuracy\n",
        "\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "aqE-byyPniCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Hsl8ztbX6zDs"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим на данные."
      ],
      "metadata": {
        "id": "N-X8tTu4Y08m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/NNmethods/Fake.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ubmdZ0axYikv",
        "outputId": "62febe4c-9b03-4068-96b7-f5abdb531092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3771eb14-35a0-4840-9c21-15543ef77727\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
              "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 31, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
              "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 31, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
              "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 30, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
              "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 29, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
              "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 25, 2017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3771eb14-35a0-4840-9c21-15543ef77727')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3771eb14-35a0-4840-9c21-15543ef77727 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3771eb14-35a0-4840-9c21-15543ef77727');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               title  ...               date\n",
              "0   Donald Trump Sends Out Embarrassing New Year’...  ...  December 31, 2017\n",
              "1   Drunk Bragging Trump Staffer Started Russian ...  ...  December 31, 2017\n",
              "2   Sheriff David Clarke Becomes An Internet Joke...  ...  December 30, 2017\n",
              "3   Trump Is So Obsessed He Even Has Obama’s Name...  ...  December 29, 2017\n",
              "4   Pope Francis Just Called Out Donald Trump Dur...  ...  December 25, 2017\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.value_counts('subject')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMGcbZvyYrMv",
        "outputId": "5fed7477-2dab-466c-fd57-90392513fe53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "subject\n",
              "News               9050\n",
              "politics           6841\n",
              "left-news          4459\n",
              "Government News    1570\n",
              "US_News             783\n",
              "Middle-east         778\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['subjectnum'] = df.subject.astype('category').cat.codes"
      ],
      "metadata": {
        "id": "DE8j12Hfmow6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выше мы видим классы новостей. Они, к сожалению, очень неравноценные."
      ],
      "metadata": {
        "id": "l8l7xh3SY3-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Препроцессинг: приводим тексты к нижнему регистру и токенизируем."
      ],
      "metadata": {
        "id": "eLr7Sf4QZC6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    return ' '.join(word_tokenize(text.lower()))"
      ],
      "metadata": {
        "id": "Qe6bZkNeY89k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['processed'] = df['text'].apply(preprocess)"
      ],
      "metadata": {
        "id": "96ne8Dg9ZH2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Уберем из датасета дубли."
      ],
      "metadata": {
        "id": "QrWE3XQBdXB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "1gEfwcdQcfnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поделим датасет на тестовую и обучающую выборки."
      ],
      "metadata": {
        "id": "Cahu5mH9az7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, val_data = train_test_split(df, test_size=0.2, shuffle=True)"
      ],
      "metadata": {
        "id": "FZYpEwFCa4uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Делаем word2id словарь."
      ],
      "metadata": {
        "id": "3o33ramEcdma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = Counter()\n",
        "for text in df['processed']:\n",
        "    vocab.update(text.split())\n",
        "print('уникальных слов:', len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7allufodHD_",
        "outputId": "3ae39dfd-53d3-4ea1-ad69-e012db014b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "уникальных слов: 181384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_vocab = set()\n",
        "for word in vocab:\n",
        "    if vocab[word] > 2:\n",
        "        filtered_vocab.add(word)\n",
        "print('уникальных слов, втретившихся больше 2 раз:', len(filtered_vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RrZs_rneTqZ",
        "outputId": "b448b35d-fa81-42a1-bbbc-82ffaa562729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "уникальных слов, втретившихся больше 2 раз: 59638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2id = {'UNK': 0}\n",
        "for word in filtered_vocab:\n",
        "    word2id[word] = len(word2id)\n",
        "id2word = {i:word for word, i in word2id.items()}"
      ],
      "metadata": {
        "id": "8Y_1zRzVeRGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "W2V модель"
      ],
      "metadata": {
        "id": "Avmz5LDSfZX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pl20oM4Jev8F",
        "outputId": "588f54a4-b142-4b11-eb26-f9728fbdba65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-29 20:27:20--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 54.231.133.248\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|54.231.133.248|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin.gz', binary=True)"
      ],
      "metadata": {
        "id": "hn-Xflsneyug"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = np.zeros((len(word2id), 300))\n",
        "\n",
        "for word, i in word2id.items():\n",
        "    try:\n",
        "        weights[i] = w2v_model[word]\n",
        "    except KeyError:\n",
        "        weights[i] = torch.FloatTensor((300,)).uniform_(-0.25, 0.25)\n",
        "\n",
        "weights = torch.FloatTensor(weights)"
      ],
      "metadata": {
        "id": "wTFoDpAMe_SD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del w2v_model"
      ],
      "metadata": {
        "id": "_RkjNmr73jXk"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Датасет"
      ],
      "metadata": {
        "id": "cGHYTjpEeVN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataSet(Dataset):\n",
        "    def __init__(self, dataset, word2id, max_len, device):\n",
        "        self.dataset = dataset['processed'].values\n",
        "        self.word2id = word2id\n",
        "        self.length = dataset.shape[0]\n",
        "        self.device = device\n",
        "        self.max_len = max_len\n",
        "        self.target = torch.Tensor(dataset['subjectnum'].values)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index): \n",
        "        tokens = self.dataset[index].split()\n",
        "        ids = torch.LongTensor([self.word2id[token] if token in self.word2id else self.word2id['UNK'] for token in tokens][:self.max_len])\n",
        "        y = [self.target[index]]\n",
        "        return ids, y\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "      ids, y = list(zip(*batch))\n",
        "      padded_ids = torch.vstack([F.pad(seq, pad=(0, self.max_len - seq.shape[0]), mode='constant', value=0) for seq in ids])\n",
        "      padded_ids = pad_sequence(ids, batch_first=True).to(self.device)\n",
        "      y = torch.LongTensor(y).to(self.device)\n",
        "      return padded_ids, y.T[0]"
      ],
      "metadata": {
        "id": "fTPd6LeB2mXa"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(train_data['processed'].str.split().apply(len))\n",
        "max_len"
      ],
      "metadata": {
        "id": "r62aF1zo6v51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8183a72a-2973-4a81-afb2-3657154107c8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8886"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Такой max_len - слишком большой для моей gpu... Придется, вопреки статье, взять меньше."
      ],
      "metadata": {
        "id": "nWIYpnzIbTah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 500"
      ],
      "metadata": {
        "id": "DOmThB8gbZ1b"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = DataSet(dataset=train_data, word2id=word2id, max_len=max_len, device=DEVICE)\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "train_iterator = DataLoader(train_dataset, collate_fn = train_dataset.collate_fn, sampler=train_sampler, batch_size=128)"
      ],
      "metadata": {
        "id": "0rhyclshbntV"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = DataSet(dataset=val_data, word2id=word2id, max_len=max_len, device=DEVICE)\n",
        "val_sampler = SequentialSampler(val_dataset)\n",
        "val_iterator = DataLoader(val_dataset, collate_fn=val_dataset.collate_fn, sampler=val_sampler, batch_size=128)"
      ],
      "metadata": {
        "id": "44C9AWaubn2E"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель"
      ],
      "metadata": {
        "id": "2Ufi44C1ft9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class C_LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, weights=weights, \n",
        "                 vocab_size=len(word2id),\n",
        "                 embedding_dim=300,\n",
        "                 max_length=max_len,\n",
        "                 output_dim=6,\n",
        "                 filter_sizes=[2, 3, 4],\n",
        "                 num_filters=150,\n",
        "                 lstm_layers=1,\n",
        "                 memory_dim=150,\n",
        "                 dropout_input=False,\n",
        "                 dropout_lstm=True,\n",
        "                 dropout_rate=0.5):\n",
        "\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding = nn.Embedding.from_pretrained(weights)\n",
        "        self.max_length = max_length\n",
        "        self.filter_sizes = filter_sizes\n",
        "        self.cnn_layers = len(filter_sizes)\n",
        "        self.max_features = max_length - max(filter_sizes) + 1\n",
        "        self.dropout_input = dropout_input\n",
        "        self.dropout_lstm = dropout_lstm\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "        windows = []\n",
        "        for filter_size in filter_sizes:\n",
        "            conv = nn.Conv1d(in_channels=embedding_dim,\n",
        "                             out_channels=num_filters,\n",
        "                             kernel_size=filter_size, \n",
        "                             padding='valid')\n",
        "            windows.append(conv)\n",
        "        self.windows = nn.ModuleList(windows)\n",
        "        self.lstm = nn.LSTM(input_size=len(filter_sizes) * num_filters,\n",
        "                            hidden_size=memory_dim,\n",
        "                            num_layers=lstm_layers,\n",
        "                            batch_first=True)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linnear = nn.Linear(in_features=memory_dim,\n",
        "                                out_features=output_dim)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "def forward(self, word):\n",
        "\n",
        "        embedded = self.embedding(word)\n",
        "        embedded = embedded.transpose(1, 2)\n",
        "        if self.dropout_input:\n",
        "            embedded = self.dropout(embedded)\n",
        "\n",
        "        feature_maps = []\n",
        "        for conv in self.conv_layers:\n",
        "            feature_map = self.relu(conv(embedded))[:, :, :self.max_features]\n",
        "            feature_maps.append(feature_map)\n",
        "\n",
        "        if self.cnn_layers > 1:\n",
        "            rnn_input = torch.cat(feature_maps, 1).transpose(1, 2)\n",
        "        else:\n",
        "            rnn_input = feature_map.transpose(1, 2)\n",
        "\n",
        "        _, (hidden_state, _) = self.lstm(rnn_input)\n",
        "        if self.dropout_lstm:\n",
        "            embedded = self.dropout(hidden_state)\n",
        "        logits = self.out(self.hidden(torch.squeeze(hidden_state, 0)))\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "atQb1l16qsg_"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, metric, n_epoch):\n",
        "\n",
        "    progress_bar = tqdm(total=len(train_iterator.dataset),\n",
        "                        desc='Epoch {}'.format(n_epoch + 1))\n",
        "\n",
        "    epoch_losses = []  \n",
        "    epoch_metrics = []\n",
        "    model.train() \n",
        "\n",
        "    for i, (texts, ys) in enumerate(iterator):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(texts) \n",
        "        loss = criterion(preds, ys)  \n",
        "        loss.backward() \n",
        "        optimizer.step() \n",
        "        epoch_losses.append(loss.item())\n",
        "        batch_metric = metric(preds.argmax(1).long(), ys.long(),\n",
        "                              average='weighted', num_classes=6,\n",
        "                              ignore_index=0)\n",
        "        epoch_metrics.append(batch_metric.cpu().numpy())\n",
        "\n",
        "        progress_bar.update(texts.shape[0])\n",
        "\n",
        "    progress_bar.close()\n",
        "    \n",
        "    return epoch_losses, epoch_metrics"
      ],
      "metadata": {
        "id": "KvVw1nPTvecv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion, n_epoch, metric):\n",
        "\n",
        "    epoch_losses = []\n",
        "    epoch_metrics = []\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i, (texts, ys) in enumerate(iterator):\n",
        "            preds = model(texts)\n",
        "            loss = criterion(preds, ys)\n",
        "\n",
        "            epoch_losses.append(loss.item())\n",
        "            batch_metric = metric(preds.argmax(1).long(), ys.long(),\n",
        "                                  average='weighted', num_classes=6,\n",
        "                                  ignore_index=0)\n",
        "            epoch_metrics.append(batch_metric.cpu().numpy())\n",
        "\n",
        "    return epoch_losses, epoch_metrics"
      ],
      "metadata": {
        "id": "un599irwwMEP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, train_iterator, val_iterator,\n",
        "                       optimizer, criterion, metric, epochs):\n",
        "    train_losses = []\n",
        "    train_metrics = []\n",
        "    eval_losses = []\n",
        "    eval_metrics = []\n",
        "\n",
        "    for n_epoch in range(epochs):\n",
        "\n",
        "        print('\\nTraining...')\n",
        "        train_loss, train_metric = train(model, train_iterator,\n",
        "                                            optimizer, criterion,\n",
        "                                            metric, n_epoch)\n",
        "        train_losses.append(train_loss)\n",
        "        train_metrics.append(train_metric)\n",
        "\n",
        "        print('\\nValidating...\\n')\n",
        "        eval_loss, eval_metric = evaluate(model, val_iterator,\n",
        "                                             criterion, n_epoch,\n",
        "                                             metric)\n",
        "        eval_losses.append(eval_loss)\n",
        "        eval_metrics.append(eval_metric)\n",
        "\n",
        "    return train_losses, eval_losses, train_metrics, eval_metrics"
      ],
      "metadata": {
        "id": "NqYHPss9wO7L"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_lstm = C_LSTM()\n",
        "optimizer = torch.optim.RMSprop(c_lstm.parameters(), lr=0.001,\n",
        "                                weight_decay=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "c_lstm = c_lstm.to(DEVICE)\n",
        "criterion = criterion.to(DEVICE)"
      ],
      "metadata": {
        "id": "2ccs9VudzPQt"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses_train, losses_eval, metrics_train, metrics_eval = train_and_evaluate(c_lstm, train_iterator, val_iterator, optimizer, criterion, accuracy, epochs=3)"
      ],
      "metadata": {
        "id": "h-ob6lxfzXyK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410,
          "referenced_widgets": [
            "eda05b73dbdb493c80caf702a69910a7",
            "25b25743916d4577aeb80fd019b87565",
            "5cb300d3565045e8acf04defc9c6538b",
            "3c610d758f32485c9369d1b2feba51ff",
            "b701d8da808a4472bf98b621707454c4",
            "01f133cb0b3c44c89f9494c324a84bab",
            "087c1c5ce3554448931d85f77fb816ae",
            "9592175843e7493cb966c56440c70a26",
            "d4b6751654304ed2a11384e95a3880d4",
            "65c382420f22402fa2bfd0bc39d33bd3",
            "b95aa615b5054fca948342d40695ca2c"
          ]
        },
        "outputId": "1b71c37b-1835-4c86-bf72-7b726ac67000"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eda05b73dbdb493c80caf702a69910a7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Epoch 1:   0%|          | 0/18782 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-dc70afed76ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlosses_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-376c40c93b0b>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model, train_iterator, val_iterator, optimizer, criterion, metric, epochs)\u001b[0m\n\u001b[1;32m     11\u001b[0m         train_loss, train_metric = train(model, train_iterator,\n\u001b[1;32m     12\u001b[0m                                             \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                                             metric, n_epoch)\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtrain_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-508e626ebcf8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, metric, n_epoch)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \"\"\"\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(train_loss, train_metric, val_loss, val_metric):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.grid()\n",
        "    \n",
        "    plt.plot(train_loss)\n",
        "    plt.plot(train_metric)\n",
        "    \n",
        "    plt.title('Training')\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylabel('Score')\n",
        "    \n",
        "    plt.legend(['loss', 'accuracy'], loc='upper right')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.grid()\n",
        "    \n",
        "    plt.plot(val_loss)\n",
        "    plt.plot(val_metric)\n",
        "    plt.title('Validation')\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylabel('Score')\n",
        "    \n",
        "    \n",
        "    plt.legend(['loss', 'accuracy'], loc='upper right')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "HBPKGQsEzbxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_train_and_eval(losses_train, losses_eval, metrics_train, metrics_eval)"
      ],
      "metadata": {
        "id": "eQM5WXejze2E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}